{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2 GCN.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOBOfiCjlUD5pEdmpouhZst",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/musicjae/GNN/blob/main/2_GCN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylCQKW87sEK_"
      },
      "source": [
        "원문: https://github.com/emergx/gnn-tutorials/blob/master/1_gcn.ipynb  \n",
        "paper: https://arxiv.org/pdf/1609.02907.pdf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R41C8jcSr_-F",
        "outputId": "ad801d5b-69c3-4b33-8b63-51c024b81ee0"
      },
      "source": [
        "!pip install networkx\n",
        "!pip install dgl"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (2.5)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx) (4.4.2)\n",
            "Collecting dgl\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/62/da7146c0e46f93dd1f17cccea3010def155a1f479c0b036b604e952f321f/dgl-0.5.3-cp36-cp36m-manylinux1_x86_64.whl (3.6MB)\n",
            "\u001b[K     |████████████████████████████████| 3.6MB 11.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.6/dist-packages (from dgl) (2.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from dgl) (2.23.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from dgl) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from dgl) (1.18.5)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.1->dgl) (4.4.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->dgl) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->dgl) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->dgl) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->dgl) (2020.11.8)\n",
            "Installing collected packages: dgl\n",
            "Successfully installed dgl-0.5.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Z5-dipOsVkY"
      },
      "source": [
        "- 메시지 패싱 관점에서 GCN  \n",
        " - 이웃 표현neighbor'srepresentations $h_v$를 중간 표현 $\\hat{h_u}$를 만들기 위해 총합한다. 총합된 표현 $\\hat{h_u}$을 선형 투영 뒤에 따라 나오는 비선형성인 $h_u = f(W_u\\hat{h_u})$으로 변환해준다.\n",
        "   \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hfl56B6ytY12"
      },
      "source": [
        "과정  \n",
        "  \n",
        "-  message 정의  \n",
        "-  평범한 함수로 바꿔줌"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIhzqvwmtrI0"
      },
      "source": [
        "# 1 임포트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peKHSs_ksHBU"
      },
      "source": [
        "import dgl\n",
        "import dgl.function as fn\n",
        "import torch as th\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from dgl import DGLGraph"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrDc301TuBPh"
      },
      "source": [
        "gcn_msg = fn.copy_src(src='h', out='m')\n",
        "gcn_reduce = fn.sum(msg='m', out='h')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POMTVm1AuV-S"
      },
      "source": [
        " A GCNLayer essentially performs message passing on all the nodes then applies a fully-connected layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-RJH2J2ts4f"
      },
      "source": [
        "class GCNLayer(nn.Module):\n",
        "    def __init__(self, in_feats, out_feats):\n",
        "        super(GCNLayer, self).__init__()\n",
        "        self.linear = nn.Linear(in_feats, out_feats) # Fcnet\n",
        "\n",
        "    def forward(self, g, feature):\n",
        "        # Creating a local scope so that all the stored ndata and edata\n",
        "        # (such as the `'h'` ndata below) are automatically popped out\n",
        "        # when the scope exits.\n",
        "        with g.local_scope():\n",
        "            g.ndata['h'] = feature\n",
        "            g.update_all(gcn_msg, gcn_reduce)\n",
        "            h = g.ndata['h']\n",
        "            return self.linear(h)\n",
        "        "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTatrs9KvIpH"
      },
      "source": [
        "cora dataset (the input feature size is 1433 and the number of classes is 7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTodCy34vBI4",
        "outputId": "cc61876c-7233-475c-fc51-077bb3f3575b"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.layer1 = GCNLayer(1433, 16)\n",
        "        self.layer2 = GCNLayer(16, 7)\n",
        "    \n",
        "    def forward(self, g, features):\n",
        "        x = F.relu(self.layer1(g, features))\n",
        "        x = self.layer2(g, x)\n",
        "        return x\n",
        "net = Net()\n",
        "print(net)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (layer1): GCNLayer(\n",
            "    (linear): Linear(in_features=1433, out_features=16, bias=True)\n",
            "  )\n",
            "  (layer2): GCNLayer(\n",
            "    (linear): Linear(in_features=16, out_features=7, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fae6XMsfvlBe"
      },
      "source": [
        "from dgl.data import citation_graph as citegrh\n",
        "import networkx as nx\n",
        "\n",
        "def load_cora_data():\n",
        "    data = citegrh.load_cora()\n",
        "    features = th.FloatTensor(data.features)\n",
        "    labels = th.LongTensor(data.labels)\n",
        "    train_mask = th.BoolTensor(data.train_mask)\n",
        "    test_mask = th.BoolTensor(data.test_mask)\n",
        "    g = DGLGraph(data.graph)\n",
        "    return g, features, labels, train_mask, test_mask\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlMsaKshv_jV"
      },
      "source": [
        "## 평가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHiVxizpwAfC"
      },
      "source": [
        "def evaluate(model, g, features, labels, mask):\n",
        "    model.eval()\n",
        "    with th.no_grad():\n",
        "        logits = model(g, features)\n",
        "        logits = logits[mask]\n",
        "        labels = labels[mask]\n",
        "        _, indices = th.max(logits, dim=1)\n",
        "        correct = th.sum(indices == labels)\n",
        "        return correct.item() * 1.0 / len(labels)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6U4ZmInqwFfQ",
        "outputId": "13fa237b-a24b-4dfa-b326-8fd6bdcac2cb"
      },
      "source": [
        "import time\n",
        "import numpy as np\n",
        "g, features, labels, train_mask, test_mask = load_cora_data()\n",
        "# Add edges between each node and itself to preserve old node representations\n",
        "g.add_edges(g.nodes(), g.nodes())\n",
        "optimizer = th.optim.Adam(net.parameters(), lr=1e-2)\n",
        "dur = []\n",
        "for epoch in range(50):\n",
        "    if epoch >=3:\n",
        "        t0 = time.time()\n",
        "\n",
        "    net.train()\n",
        "    logits = net(g, features)\n",
        "    logp = F.log_softmax(logits, 1)\n",
        "    loss = F.nll_loss(logp[train_mask], labels[train_mask])\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    if epoch >=3:\n",
        "        dur.append(time.time() - t0)\n",
        "    \n",
        "    acc = evaluate(net, g, features, labels, test_mask)\n",
        "    print(\"Epoch {:05d} | Loss {:.4f} | Test Acc {:.4f} | Time(s) {:.4f}\".format(\n",
        "            epoch, loss.item(), acc, np.mean(dur)))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading from cache failed, re-processing.\n",
            "Finished data loading and preprocessing.\n",
            "  NumNodes: 2708\n",
            "  NumEdges: 10556\n",
            "  NumFeats: 1433\n",
            "  NumClasses: 7\n",
            "  NumTrainingSamples: 140\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "Done saving data into cached files.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/dgl/data/utils.py:285: UserWarning: Property dataset.feat will be deprecated, please use g.ndata['feat'] instead.\n",
            "  warnings.warn('Property {} will be deprecated, please use {} instead.'.format(old, new))\n",
            "/usr/local/lib/python3.6/dist-packages/dgl/data/utils.py:285: UserWarning: Property dataset.label will be deprecated, please use g.ndata['label'] instead.\n",
            "  warnings.warn('Property {} will be deprecated, please use {} instead.'.format(old, new))\n",
            "/usr/local/lib/python3.6/dist-packages/dgl/data/utils.py:285: UserWarning: Property dataset.train_mask will be deprecated, please use g.ndata['train_mask'] instead.\n",
            "  warnings.warn('Property {} will be deprecated, please use {} instead.'.format(old, new))\n",
            "/usr/local/lib/python3.6/dist-packages/dgl/data/utils.py:285: UserWarning: Property dataset.test_mask will be deprecated, please use g.ndata['test_mask'] instead.\n",
            "  warnings.warn('Property {} will be deprecated, please use {} instead.'.format(old, new))\n",
            "/usr/local/lib/python3.6/dist-packages/dgl/data/utils.py:285: UserWarning: Property dataset.graph will be deprecated, please use dataset[0] instead.\n",
            "  warnings.warn('Property {} will be deprecated, please use {} instead.'.format(old, new))\n",
            "/usr/local/lib/python3.6/dist-packages/dgl/base.py:45: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.\n",
            "  return warnings.warn(message, category=category, stacklevel=1)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 00000 | Loss 1.9595 | Test Acc 0.3740 | Time(s) nan\n",
            "Epoch 00001 | Loss 1.8513 | Test Acc 0.4180 | Time(s) nan\n",
            "Epoch 00002 | Loss 1.7336 | Test Acc 0.4840 | Time(s) nan\n",
            "Epoch 00003 | Loss 1.6334 | Test Acc 0.5330 | Time(s) 0.0540\n",
            "Epoch 00004 | Loss 1.5279 | Test Acc 0.5810 | Time(s) 0.0518\n",
            "Epoch 00005 | Loss 1.4311 | Test Acc 0.6320 | Time(s) 0.0517\n",
            "Epoch 00006 | Loss 1.3406 | Test Acc 0.6730 | Time(s) 0.0515\n",
            "Epoch 00007 | Loss 1.2509 | Test Acc 0.7400 | Time(s) 0.0513\n",
            "Epoch 00008 | Loss 1.1595 | Test Acc 0.7810 | Time(s) 0.0511\n",
            "Epoch 00009 | Loss 1.0688 | Test Acc 0.7730 | Time(s) 0.0517\n",
            "Epoch 00010 | Loss 0.9821 | Test Acc 0.7600 | Time(s) 0.0515\n",
            "Epoch 00011 | Loss 0.9013 | Test Acc 0.7560 | Time(s) 0.0513\n",
            "Epoch 00012 | Loss 0.8262 | Test Acc 0.7580 | Time(s) 0.0513\n",
            "Epoch 00013 | Loss 0.7558 | Test Acc 0.7580 | Time(s) 0.0513\n",
            "Epoch 00014 | Loss 0.6900 | Test Acc 0.7660 | Time(s) 0.0511\n",
            "Epoch 00015 | Loss 0.6287 | Test Acc 0.7680 | Time(s) 0.0511\n",
            "Epoch 00016 | Loss 0.5718 | Test Acc 0.7670 | Time(s) 0.0510\n",
            "Epoch 00017 | Loss 0.5197 | Test Acc 0.7650 | Time(s) 0.0509\n",
            "Epoch 00018 | Loss 0.4727 | Test Acc 0.7640 | Time(s) 0.0513\n",
            "Epoch 00019 | Loss 0.4304 | Test Acc 0.7540 | Time(s) 0.0512\n",
            "Epoch 00020 | Loss 0.3922 | Test Acc 0.7520 | Time(s) 0.0511\n",
            "Epoch 00021 | Loss 0.3575 | Test Acc 0.7500 | Time(s) 0.0512\n",
            "Epoch 00022 | Loss 0.3263 | Test Acc 0.7510 | Time(s) 0.0512\n",
            "Epoch 00023 | Loss 0.2980 | Test Acc 0.7490 | Time(s) 0.0511\n",
            "Epoch 00024 | Loss 0.2724 | Test Acc 0.7510 | Time(s) 0.0511\n",
            "Epoch 00025 | Loss 0.2491 | Test Acc 0.7490 | Time(s) 0.0511\n",
            "Epoch 00026 | Loss 0.2279 | Test Acc 0.7500 | Time(s) 0.0510\n",
            "Epoch 00027 | Loss 0.2084 | Test Acc 0.7510 | Time(s) 0.0510\n",
            "Epoch 00028 | Loss 0.1908 | Test Acc 0.7540 | Time(s) 0.0511\n",
            "Epoch 00029 | Loss 0.1746 | Test Acc 0.7550 | Time(s) 0.0510\n",
            "Epoch 00030 | Loss 0.1599 | Test Acc 0.7540 | Time(s) 0.0510\n",
            "Epoch 00031 | Loss 0.1466 | Test Acc 0.7530 | Time(s) 0.0510\n",
            "Epoch 00032 | Loss 0.1345 | Test Acc 0.7540 | Time(s) 0.0511\n",
            "Epoch 00033 | Loss 0.1234 | Test Acc 0.7500 | Time(s) 0.0512\n",
            "Epoch 00034 | Loss 0.1134 | Test Acc 0.7470 | Time(s) 0.0511\n",
            "Epoch 00035 | Loss 0.1043 | Test Acc 0.7470 | Time(s) 0.0511\n",
            "Epoch 00036 | Loss 0.0960 | Test Acc 0.7480 | Time(s) 0.0511\n",
            "Epoch 00037 | Loss 0.0884 | Test Acc 0.7490 | Time(s) 0.0511\n",
            "Epoch 00038 | Loss 0.0816 | Test Acc 0.7490 | Time(s) 0.0510\n",
            "Epoch 00039 | Loss 0.0754 | Test Acc 0.7490 | Time(s) 0.0510\n",
            "Epoch 00040 | Loss 0.0697 | Test Acc 0.7470 | Time(s) 0.0511\n",
            "Epoch 00041 | Loss 0.0645 | Test Acc 0.7460 | Time(s) 0.0511\n",
            "Epoch 00042 | Loss 0.0598 | Test Acc 0.7450 | Time(s) 0.0511\n",
            "Epoch 00043 | Loss 0.0555 | Test Acc 0.7440 | Time(s) 0.0511\n",
            "Epoch 00044 | Loss 0.0516 | Test Acc 0.7460 | Time(s) 0.0512\n",
            "Epoch 00045 | Loss 0.0480 | Test Acc 0.7460 | Time(s) 0.0512\n",
            "Epoch 00046 | Loss 0.0447 | Test Acc 0.7460 | Time(s) 0.0512\n",
            "Epoch 00047 | Loss 0.0417 | Test Acc 0.7460 | Time(s) 0.0512\n",
            "Epoch 00048 | Loss 0.0390 | Test Acc 0.7430 | Time(s) 0.0512\n",
            "Epoch 00049 | Loss 0.0365 | Test Acc 0.7430 | Time(s) 0.0511\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}